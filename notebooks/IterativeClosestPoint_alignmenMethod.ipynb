{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob\n",
    "import rosbag\n",
    "import rospy\n",
    "from urdf_parser_py.urdf import URDF\n",
    "from pykdl_utils.kdl_parser import kdl_tree_from_urdf_model\n",
    "from pykdl_utils.kdl_kinematics import KDLKinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './Robot_ViconOctober/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Vicon and camera dynamic data\n",
    "## Load Vicon data\n",
    "vicobags_dyna = glob.glob(data_path+'ViconDynamicDataOct/*.bag')\n",
    "for i,bag in enumerate(vicobags_dyna): # loop over vicon bags\n",
    "    vdbag = rosbag.Bag(bag)\n",
    "    vicon_dynaXpos = []\n",
    "    vicon_dynaYpos = []\n",
    "    vicon_dynaZpos = []\n",
    "    viconbag_time_dyna = []\n",
    "    for topicc, msgg, tt in vdbag.read_messages(topics=['/vicon/packbot_endEff/packbot_endEff']): # extract data\n",
    "        vicon_dynaXpos.append(msgg.transform.translation.x)\n",
    "        vicon_dynaYpos.append(msgg.transform.translation.y)\n",
    "        vicon_dynaZpos.append(msgg.transform.translation.z) \n",
    "        vicon_time_dy = tt.secs\n",
    "        viconbag_time_dyna.append(vicon_time_dy)\n",
    "    vdbag.close()\n",
    "\n",
    "    vicon_dynaXPosArr = np.array(vicon_dynaXpos)\n",
    "    vicon_dynaYPosArr = np.array(vicon_dynaYpos)\n",
    "    vicon_dynaZPosArr = np.array(vicon_dynaZpos)\n",
    "    vicon_dynaPosArr = np.column_stack((vicon_dynaXPosArr,vicon_dynaYPosArr,vicon_dynaZPosArr)) \n",
    "    np.save(data_path+'vicon_dynaPosArr%d.npy'%i, vicon_dynaPosArr) # save to numpy\n",
    "    np.save(data_path+'viconbag_time_dyna%d.npy'%i, viconbag_time_dyna)\n",
    "    \n",
    "# Load Robot data    \n",
    "robobags_dyna = glob.glob(data_path+'RobotDynamicDataOct/*.bag')\n",
    "for i,bag in enumerate(robobags_dyna): # loop over robot bags\n",
    "    rdbag = rosbag.Bag(bag)\n",
    "    robot_dynaXpos = []\n",
    "    robot_dynaYpos = []\n",
    "    robot_dynaZpos = []\n",
    "    robotbag_Tagtime_dyna = [] # \\this was spelt wrong\n",
    "    for topi, msgs, tym in rdbag.read_messages(topics=['/tag_detections']): # extract data\n",
    "        try:\n",
    "            robot_dynaXpos.append(msgs.detections[0].pose.pose.pose.position.x)\n",
    "            robot_dynaYpos.append(msgs.detections[0].pose.pose.pose.position.y)\n",
    "            robot_dynaZpos.append(msgs.detections[0].pose.pose.pose.position.z)   \n",
    "            robotbag_Tagtime_dyna.append(tym.secs)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    robot_dynaXposArr = np.array(robot_dynaXpos)\n",
    "    robot_dynaYposArr = np.array(robot_dynaYpos)\n",
    "    robot_dynaZposArr = np.array(robot_dynaZpos)\n",
    "    robot_dynaposArr = np.column_stack((robot_dynaXposArr,robot_dynaYposArr,robot_dynaZposArr))\n",
    "    np.save(data_path+'robot_dynaPosArr%d.npy'%i, robot_dynaposArr)\n",
    "    np.save(data_path+'robotbag_Tagtime_dyna%d.npy'%i, robotbag_Tagtime_dyna)\n",
    "    \n",
    "    \n",
    "    robotbag_Jointstime_dyna = []\n",
    "    ja_list = []\n",
    "    for topic2, msg2, t2 in rdbag.read_messages(topics=['/Packbot510/joints']):\n",
    "        ja_list.append(msg2.position[:3])\n",
    "        robotbag_Jointstime_dyna.append(t2.secs)\n",
    "    ja_array_dyna = np.array(ja_list)\n",
    "    rdbag.close()\n",
    "    np.save(data_path+'ja_array_dyna%d.npy'%i, ja_array_dyna)\n",
    "    np.save(data_path+'robotbag_Jointstime_dyna%d.npy'%i, robotbag_Jointstime_dyna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check loading data we just saved\n",
    "vicon_dylist = []\n",
    "camera_dylist = []\n",
    "kinematics_list_dyna = []\n",
    "\n",
    "tk = []\n",
    "tc = []\n",
    "tv = []\n",
    "\n",
    "for i in range(len(vicobags_dyna)):\n",
    "    vicon_dy = np.load(data_path+'vicon_dynaPosArr%d.npy'%i)\n",
    "    vicon_dylist.append(vicon_dy)\n",
    "    v_time = np.load(data_path+'viconbag_time_dyna%d.npy'%i) # Name was wrong. missing dyna\n",
    "    tv.append(v_time)\n",
    "   \n",
    "    robot_dy = np.load(data_path+'robot_dynaPosArr%d.npy'%i)\n",
    "    camera_dylist.append(robot_dy)\n",
    "    c_time = np.load(data_path+'robotbag_Tagtime_dyna%d.npy'%i) # Name was wrong. missing dyna\n",
    "    tc.append(c_time)\n",
    "    \n",
    "    RobotKin_dy = np.load(data_path+'ja_array_dyna%d.npy'%i)\n",
    "    kinematics_list_dyna.append(RobotKin_dy)\n",
    "    k_time = np.load(data_path+'robotbag_Jointstime_dyna%d.npy'%i)\n",
    "    tk.append(k_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = URDF.from_xml_file('robot.urdf')\n",
    "links = [rl.name for rl in robot.links]\n",
    "kdl_kin_dy = KDLKinematics(robot,'base_link','elbow2_link')\n",
    "#print(kdl_kin.get_joint_names())\n",
    "\n",
    "BaseTo_ee_xyz_dyna = []\n",
    "for dy in kinematics_list_dyna:\n",
    "    ee_list_dy = []\n",
    "    for joints in dy:\n",
    "        posez_dy = kdl_kin_dy.forward(joints)\n",
    "        ee_list_dy.append(posez_dy[0:3,3])\n",
    "    BaseTo_ee_xyz_dyna.append(np.squeeze(np.array(ee_list_dy)))\n",
    "np.save(data_path+'BaseTo_ee_xyz_dyna%d.npy'%i, BaseTo_ee_xyz_dyna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_fit_transform(A, B):\n",
    "    '''\n",
    "    Calculates the least-squares best-fit transform that maps corresponding points A to B in m spatial dimensions\n",
    "    Input:\n",
    "      A: Nxm numpy array of corresponding points\n",
    "      B: Nxm numpy array of corresponding points\n",
    "    Returns:\n",
    "      T: (m+1)x(m+1) homogeneous transformation matrix that maps A on to B\n",
    "      R: mxm rotation matrix\n",
    "      t: mx1 translation vector\n",
    "    '''\n",
    "    \n",
    "    #assert A.shape == B.shape  ####commented  all the assert statements \n",
    "                                ####coz they were gving me shape erros whereas the datasets shapes were the same,\n",
    "\n",
    "    # get number of dimensions\n",
    "    m = A.shape[1]\n",
    "\n",
    "    # translate points to their centroids\n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "    AA = A - centroid_A\n",
    "    BB = B - centroid_B\n",
    "\n",
    "    # rotation matrix\n",
    "    H = np.dot(AA.T, BB)\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R = np.dot(Vt.T, U.T)\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "       Vt[m-1,:] *= -1\n",
    "       R = np.dot(Vt.T, U.T)\n",
    "\n",
    "    # translation\n",
    "    t = centroid_B.T - np.dot(R,centroid_A.T)\n",
    "\n",
    "    # homogeneous transformation\n",
    "    T = np.identity(m+1)\n",
    "    T[:m, :m] = R\n",
    "    T[:m, m] = t\n",
    "\n",
    "    return T, R, t\n",
    "\n",
    "\n",
    "def nearest_neighbor(src, dst):\n",
    "    '''\n",
    "    Find the nearest (Euclidean) neighbor in dst for each point in src\n",
    "    Input:\n",
    "        src: Nxm array of points\n",
    "        dst: Nxm array of points\n",
    "    Output:\n",
    "        distances: Euclidean distances of the nearest neighbor\n",
    "        indices: dst indices of the nearest neighbor\n",
    "    '''\n",
    "    \n",
    "    #assert src.shape == dst.shape\n",
    "\n",
    "    neigh = NearestNeighbors(n_neighbors=1)\n",
    "    neigh.fit(dst)\n",
    "    distances, indices = neigh.kneighbors(src, return_distance=True)\n",
    "    return distances.ravel(), indices.ravel()\n",
    "\n",
    "\n",
    "def icp(A, B, init_pose=None, max_iterations=20, tolerance=0.001):\n",
    "    '''\n",
    "    The Iterative Closest Point method: finds best-fit transform that maps points A on to points B\n",
    "    Input:\n",
    "        A: Nxm numpy array of source mD points\n",
    "        B: Nxm numpy array of destination mD point\n",
    "        init_pose: (m+1)x(m+1) homogeneous transformation\n",
    "        max_iterations: exit algorithm after max_iterations\n",
    "        tolerance: convergence criteria\n",
    "    Output:\n",
    "        T: final homogeneous transformation that maps A on to B\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "        i: number of iterations to converge\n",
    "    '''\n",
    "    \n",
    "    #assert A.shape == B.shape\n",
    "\n",
    "    # get number of dimensions\n",
    "    m = A.shape[1]\n",
    "\n",
    "    # make points homogeneous, copy them to maintain the originals\n",
    "    src = np.ones((m+1,A.shape[0]))\n",
    "    dst = np.ones((m+1,B.shape[0]))\n",
    "    src[:m,:] = np.copy(A.T)\n",
    "    dst[:m,:] = np.copy(B.T)\n",
    "\n",
    "    # apply the initial pose estimation\n",
    "    if init_pose is not None:\n",
    "        src = np.dot(init_pose, src)\n",
    "\n",
    "    prev_error = 0\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # find the nearest neighbors between the current source and destination points\n",
    "        distances, indices = nearest_neighbor(src[:m,:].T, dst[:m,:].T)\n",
    "\n",
    "        # compute the transformation between the current source and nearest destination points\n",
    "        T,_,_ = best_fit_transform(src[:m,:].T, dst[:m,indices].T)\n",
    "\n",
    "        # update the current source\n",
    "        src = np.dot(T, src)\n",
    "\n",
    "        # check error\n",
    "        mean_error = np.mean(distances)\n",
    "        if np.abs(prev_error - mean_error) < tolerance:\n",
    "            break\n",
    "        prev_error = mean_error\n",
    "\n",
    "    # calculate final transformation\n",
    "    T,_,_ = best_fit_transform(A, src[:m,:].T)\n",
    "\n",
    "    return T, distances #,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransMatrix, Dist = icp(BaseTo_ee_xyz_dyna[0],vicon_dylist[0], init_pose=None, max_iterations=20, tolerance=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,4) and (1628,3) not aligned: 4 (dim 1) != 1628 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-64bcd798ff54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Rotate Robot data into Vicon frame of reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrobot_v_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransMatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseTo_ee_xyz_dyna\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,4) and (1628,3) not aligned: 4 (dim 1) != 1628 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Rotate Robot data into Vicon frame of reference\n",
    "robot_v_list = np.dot(TransMatrix,(BaseTo_ee_xyz_dyna[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the error above Im thinking of tryng one of the two below:\n",
    "## 1. add a column of oness on the robot  data to have 4d xyz1 ? \n",
    "# or  2. use Rot  and Trans from best_fit_transform() like we did on the procrustes alignment previously?\n",
    "##2a. But Im not sure how will 2. succeed if we ommit the work done by the two functions(nearest_neighbor()&icp())\n",
    "# 2b. or will it make sense if myb I take the 4x4 TransMatrix and \n",
    "## treat TransMatrix[0:3,0:3] = 3*3 as Rot and then TransMatrixarr[3,0:3] as transla ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
